"""
Production-Ready Real-Time ETA Prediction System
Uses actual GPS data format and IIT Madras stop metadata
"""
import asyncio
import aiohttp
import numpy as np
import pickle
import xgboost as xgb
import lightgbm as lgb
from sklearn.preprocessing import StandardScaler
from datetime import datetime
from typing import Dict, List, Tuple
import logging
import math
from stop_metadata import STOPS, ROUTES, get_upcoming_stops

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('eta_predictions.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class ProductionETAPredictor:
    """
    Production-ready ETA prediction system for IIT Madras buses.
    """
    
    def __init__(self):
        """Initialize predictor with models and metadata."""
        logger.info("üöÄ Initializing Production ETA Predictor...")
        
        # Load trained models
        try:
            self.xgb_model = xgb.Booster()
            self.xgb_model.load_model('production_xgboost.json')
            
            self.lgb_model = lgb.Booster(model_file='production_lightgbm.txt')
            
            with open('production_ensemble.pkl', 'rb') as f:
                ensemble_data = pickle.load(f)
                self.meta_model = ensemble_data['meta_model']
                self.scaler = ensemble_data['scaler']
            
            logger.info("‚úÖ Models loaded successfully")
        except Exception as e:
            logger.error(f"‚ùå Failed to load models: {e}")
            raise
        
        # API endpoints
        self.vehicle_data_url = "https://traveliitmapi.mydigipin.in/api/vehicle-data"
        self.active_routes_url = "https://traveliitmapi.mydigipin.in/api/vehicle-route/active"
        
        # Cache for predictions
        self.latest_predictions = {}
        self.last_update = None
    
    def convert_to_features(self, vehicle: Dict, target_stop_id: int) -> np.ndarray:
        """
        Convert GPS data to 53-feature vector for model.
        
        Args:
            vehicle: {
                'latitude': float,
                'longitude': float,
                'speed': float,
                'timestamp': str
            }
            target_stop_id: Target stop ID
            
        Returns:
            np.ndarray of shape (53,)
        """
        target_stop = STOPS[target_stop_id]
        
        # Calculate distance to target
        distance = self._haversine_distance(
            vehicle['latitude'], vehicle['longitude'],
            target_stop['latitude'], target_stop['longitude']
        )
        
        # Extract time features
        dt = datetime.fromisoformat(vehicle['timestamp'].replace('Z', '+00:00'))
        hour = dt.hour
        day_of_week = dt.weekday()
        is_rush_hour = 1.0 if (7 <= hour <= 9) or (17 <= hour <= 19) else 0.0
        
        # Base features (8)
        base_features = np.array([
            vehicle['speed'],
            distance,
            hour,
            day_of_week,
            vehicle['latitude'],
            vehicle['longitude'],
            target_stop['latitude'],
            target_stop['longitude']
        ])
        
        # Approximate graph features (single vehicle = no variance)
        node_mean = base_features
        node_std = np.zeros(8)
        node_max = base_features
        node_min = base_features
        node_median = base_features
        target_features = base_features
        
        # Graph structure (single vehicle)
        num_nodes = 1
        num_edges = 0
        
        # Derived features
        speed_variance = 0
        dist_progression = min(distance / 5000, 1.0)  # Normalize by max campus distance
        
        # Combine all features (53 total)
        features = np.concatenate([
            node_mean,           # 8
            node_std,            # 8
            node_max,            # 8
            node_min,            # 8
            node_median,         # 8
            target_features,     # 8
            [num_nodes],         # 1
            [num_edges],         # 1
            [speed_variance],    # 1
            [dist_progression],  # 1
            [is_rush_hour]       # 1
        ])
        
        return features
    
    def _haversine_distance(self, lat1: float, lon1: float, 
                           lat2: float, lon2: float) -> float:
        """Calculate distance in meters using Haversine formula."""
        R = 6371000  # Earth radius in meters
        
        phi1 = math.radians(lat1)
        phi2 = math.radians(lat2)
        delta_phi = math.radians(lat2 - lat1)
        delta_lambda = math.radians(lon2 - lon1)
        
        a = (math.sin(delta_phi/2)**2 + 
             math.cos(phi1) * math.cos(phi2) * math.sin(delta_lambda/2)**2)
        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
        
        return R * c
    
    async def fetch_vehicle_data(self) -> List[Dict]:
        """Fetch current vehicle positions from API."""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(self.vehicle_data_url, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        logger.info(f"üì° Fetched data for {len(data)} vehicles")
                        return data
                    else:
                        logger.error(f"‚ùå API returned status {response.status}")
                        return []
        except Exception as e:
            logger.error(f"‚ùå Failed to fetch vehicle data: {e}")
            return []
    
    async def fetch_active_routes(self) -> Dict[str, str]:
        """Fetch active route mappings."""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(self.active_routes_url, timeout=10) as response:
                    if response.status == 200:
                        data = await response.json()
                        return {item['vehicleNo']: item['routeCode'] for item in data}
                    else:
                        return {}
        except Exception as e:
            logger.error(f"‚ùå Failed to fetch routes: {e}")
            return {}
    
    def clean_vehicle_data(self, vehicles: List[Dict]) -> List[Dict]:
        """Clean and validate vehicle data."""
        cleaned = []
        current_time = datetime.utcnow()
        
        for vehicle in vehicles:
            try:
                # Parse timestamp
                timestamp = datetime.fromisoformat(
                    vehicle['timestamp'].replace('Z', '+00:00')
                )
                age_seconds = (current_time - timestamp.replace(tzinfo=None)).total_seconds()
                
                # Filter stale data (>5 minutes old)
                if age_seconds > 300:
                    continue
                
                # Validate coordinates (IIT Madras bounds)
                if not (12.98 <= vehicle['latitude'] <= 13.01 and
                       80.22 <= vehicle['longitude'] <= 80.25):
                    continue
                
                cleaned.append(vehicle)
                
            except Exception as e:
                logger.debug(f"Error processing vehicle: {e}")
                continue
        
        logger.info(f"‚úÖ Cleaned: {len(cleaned)}/{len(vehicles)} vehicles valid")
        return cleaned
    
    def predict_eta(self, vehicle: Dict, stop_id: int) -> float:
        """
        Predict ETA for a vehicle to reach a stop.
        
        Returns:
            ETA in seconds
        """
        try:
            # Convert to features
            features = self.convert_to_features(vehicle, stop_id)
            
            # Scale features
            features_scaled = self.scaler.transform([features])
            
            # Get base model predictions
            xgb_pred = self.xgb_model.predict(xgb.DMatrix(features_scaled))
            lgb_pred = self.lgb_model.predict(features_scaled)
            
            # Meta-learner prediction
            meta_input = np.column_stack([xgb_pred, lgb_pred])
            eta_seconds = self.meta_model.predict(meta_input)[0]
            
            return max(0, eta_seconds)
            
        except Exception as e:
            logger.error(f"‚ùå Prediction error: {e}")
            return float('inf')
    
    async def generate_predictions(self) -> Dict[int, Dict]:
        """
        Generate predictions for all stops.
        
        Returns:
            Dict mapping stop_id to prediction info
        """
        # Fetch data
        vehicles = await self.fetch_vehicle_data()
        routes = await self.fetch_active_routes()
        
        # Clean data
        vehicles = self.clean_vehicle_data(vehicles)
        
        if not vehicles:
            logger.warning("‚ö†Ô∏è  No valid vehicle data available")
            return self.latest_predictions  # Return cached predictions
        
        # Generate predictions
        predictions = {}
        
        for vehicle in vehicles:
            vehicle_no = vehicle['vehicleno']
            route_code = routes.get(vehicle_no)
            
            if not route_code or route_code not in ROUTES:
                logger.debug(f"No valid route for vehicle {vehicle_no}")
                continue
            
            # Get upcoming stops based on position and route
            upcoming_stops = get_upcoming_stops(
                (vehicle['latitude'], vehicle['longitude']),
                route_code
            )
            
            for stop_id in upcoming_stops:
                # Predict ETA
                eta = self.predict_eta(vehicle, stop_id)
                
                # Keep minimum ETA for each stop
                if stop_id not in predictions or eta < predictions[stop_id]['eta_seconds']:
                    predictions[stop_id] = {
                        'stop_id': stop_id,
                        'stop_name': STOPS[stop_id]['name'],
                        'eta_seconds': round(eta, 1),
                        'eta_minutes': round(eta / 60, 1),
                        'vehicle_no': vehicle_no,
                        'route': route_code,
                        'route_label': ROUTES[route_code]['label'],
                        'confidence': 'high',  # 93.2% at ¬±5min
                        'last_updated': datetime.utcnow().isoformat() + 'Z'
                    }
        
        logger.info(f"‚úÖ Generated predictions for {len(predictions)} stops")
        
        # Update cache
        self.latest_predictions = predictions
        self.last_update = datetime.utcnow()
        
        return predictions
    
    def get_prediction(self, stop_id: int) -> Dict:
        """Get prediction for a specific stop."""
        return self.latest_predictions.get(stop_id, {
            'stop_id': stop_id,
            'stop_name': STOPS.get(stop_id, {}).get('name', 'Unknown'),
            'eta_seconds': None,
            'eta_minutes': None,
            'message': 'No buses currently heading to this stop',
            'last_updated': datetime.utcnow().isoformat() + 'Z'
        })
    
    async def run_continuous(self, interval_seconds: int = 60):
        """
        Run prediction loop continuously.
        
        Args:
            interval_seconds: Update interval (default 60s)
        """
        logger.info(f"üîÑ Starting continuous prediction (interval: {interval_seconds}s)")
        
        iteration = 0
        while True:
            try:
                iteration += 1
                logger.info(f"\n{'='*60}")
                logger.info(f"Iteration #{iteration} - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                logger.info(f"{'='*60}")
                
                # Generate predictions
                predictions = await self.generate_predictions()
                
                # Log summary
                if predictions:
                    etas = [p['eta_minutes'] for p in predictions.values() if p.get('eta_minutes')]
                    if etas:
                        logger.info(
                            f"üìä {len(predictions)} stops | "
                            f"ETA range: {min(etas):.1f}-{max(etas):.1f} min"
                        )
                        
                        # Log top 5 closest buses
                        sorted_preds = sorted(
                            predictions.values(),
                            key=lambda x: x.get('eta_seconds', float('inf'))
                        )[:5]
                        
                        logger.info("üöå Closest buses:")
                        for pred in sorted_preds:
                            logger.info(
                                f"   {pred['stop_name']}: {pred['eta_minutes']:.1f} min "
                                f"({pred['vehicle_no']} on {pred['route_label']})"
                            )
                
                # Wait for next interval
                await asyncio.sleep(interval_seconds)
                
            except KeyboardInterrupt:
                logger.info("\nüëã Shutting down gracefully...")
                break
            except Exception as e:
                logger.error(f"‚ùå Error in prediction loop: {e}")
                await asyncio.sleep(10)  # Wait 10s before retry


# CLI entry point
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='IIT Madras Bus ETA Prediction Service')
    parser.add_argument('--interval', type=int, default=60,
                       help='Update interval in seconds (default: 60)')
    parser.add_argument('--test', action='store_true',
                       help='Run single prediction test and exit')
    
    args = parser.parse_args()
    
    # Initialize predictor
    predictor = ProductionETAPredictor()
    
    if args.test:
        # Test mode - single prediction
        logger.info("üß™ Running test prediction...")
        predictions = asyncio.run(predictor.generate_predictions())
        
        print(f"\n‚úÖ Test complete! Generated {len(predictions)} predictions")
        if predictions:
            print("\nSample predictions:")
            for stop_id, pred in list(predictions.items())[:5]:
                print(f"  Stop {stop_id}: {pred['eta_minutes']:.1f} min")
    else:
        # Production mode - continuous
        asyncio.run(predictor.run_continuous(interval_seconds=args.interval))
